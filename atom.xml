<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <title>The Weak Learner</title>
    <link>http://weinstockj.github.io</link>
    <updated>2016-06-08T01:31:28Z</updated>
    <author>
        <name>Josh Weinstock</name>
        <email>user@example.com</email>
        <uri>http://weinstockj.github.io</uri>
    </author>
    <link rel="alternate" href="http://weinstockj.github.io"/>
    <subtitle>A blog about programming and statistics</subtitle>
    <rights>Josh Weinstock 2016</rights>
    <generator>Feed for Node.js</generator>
    <entry>
        <title type="html"><![CDATA[Reading in data in Julia, R, and Python]]></title>
        <id>http://weinstockj.github.io/blog/2016/06/04/reading-in-data-in-julia-r-and-python/</id>
        <link href="http://weinstockj.github.io/blog/2016/06/04/reading-in-data-in-julia-r-and-python/">
        </link>
        <updated>2016-06-04T02:24:29Z</updated>
        <summary type="html"><![CDATA[<p>I’ve been fairly interested in the <a href="http://julialang.org/">Julia</a> programming language recently. Haven’t heard of it? From the project website:  “Julia is a high-level, high-performance dynamic programming language for technical computing.”</p>
<p>From what I understand, it’s a programming language intended
to provide a high-level programming interface with similar
features to R / Python / Matlab at near C-level speed. Sounds
pretty intriguing right? The language is fairly new, so its ecosystem is not as mature as R’s or Python’s.</p>
<p>At my job I attempted to do some of my work in Julia a couple months back, but honestly never got much further than reading in a .csv into memory.
Anecdotally, it seemed pretty slow to read in data, as well as having very high memory usage. This gave my the sense that Julia was maybe not quite appropriate for my purposes if I couldn’t efficiently read in and store a simple .csv.
Naturally, this may have also been a result of my lack of familiarity with the language.</p>
<p>I decided to play around with the language again a couple months later, and downloaded the development version of Julia 0.5.0. The simple benchmark I came up with was:</p>
<ol>
<li>Download  this <a href="https://raw.githubusercontent.com/hadley/nycflights13/master/data-raw/airports.csv">airports data</a></li>
<li>Read in file to a data frame</li>
</ol>
<p>In R and Python I was capable of doing both steps at once,
while with Julia I had to download the file separately, and then read in the file, which is no big deal.</p>
<p>I chose this dataset, popularized by <a href="https://github.com/hadley">Hadley Wickham</a> in some of the vignettes
of his R packages. I don’t know the origins of the dataset.</p>
<p>Here are the commands I used to do this analysis:</p>
<h4 id="r-3-2-1">R 3.2.1</h4>
<pre><code>
flights = read.csv("https://raw.githubusercontent.com/hadley/nycflights13/master/data-raw/airports.csv")
pryr::object_size(flights)
</code></pre>

<h4 id="python-2-7-10">Python 2.7.10</h4>
<pre><code>
import pandas as pd
flights = pd.read_csv("https://raw.githubusercontent.com/hadley/nycflights13/master/data-raw/airports.csv")
flights.values.nbytes
</code></pre>

<h4 id="julia-0-5-0-dev">Julia 0.5.0-dev</h4>
<pre><code>
using DataFrames
download("https://raw.githubusercontent.com/hadley/nycflights13/master/data-raw/airports.csv", "airpots.csv")
df = readtable("airpots.csv")
whos(r"df")
</code></pre>

<h2 id="results">Results</h2>
<table>
<thead>
<tr>
<th>language</th>
<th>RAM</th>
<th>time (sec)</th>
</tr>
</thead>
<tbody>
<tr>
<td>R</td>
<td>235 KB</td>
<td>0.20</td>
</tr>
<tr>
<td>Python</td>
<td>78 KB</td>
<td>0.19</td>
</tr>
<tr>
<td>Julia</td>
<td>143 KB</td>
<td>5.45</td>
</tr>
</tbody>
</table>
<h3 id="caveats">Caveats</h3>
<p>My sense is that this was probably a dumb benchmark. Internet download speeds can be variable, and I didn’t run this on a very fast internet connection. For Julia I also only timed the <code>readtable</code> function and ignored the <code>download</code> aspect, out of laziness.</p>
<h2 id="discussion">Discussion</h2>
<p>According to this benchmark, R was the least efficient at storing this data in terms of memory usage. My sense is that this is probably related to the fact that R doesn’t store numeric data very efficiently since there are no primitive types. By that I mean a single integer in R will take up 48 bytes of memory, when clearly you don’t need 48 bytes to store a single integer. It’s because the resulting object is actually a vector. In Python, storing an integer (via <code>var = 1</code>) takes 24 bytes, and in Julia it takes just 8 bytes. So yea, R is 6
times less memory efficient than Julia for storing a single int. Perhaps this isn’t super relevant to this discussion because there’s a lot more going on in <code>dataframe</code> structures than that.</p>
<p>In terms of speed, clearly Julia was much slower here than R or Python. Obviously I didn’t even bother with faster R functions to read in data like <code>data.table::fread</code> or <code>readr::read_csv</code> . I don’t know very much about the data frame implementation or the <code>readtable</code> function, so I won’t hazard a guess as to why we observed this result. I will conclude by just pointing out that this was a silly benchmark, and it’s my sense that Julia was constructed with more in mind than performing well on this benchmark. This was more to satisfy my curiosity than an attempt at a serious benchmark.</p>
]]></summary>
    </entry>
    <entry>
        <title type="html"><![CDATA[First post!]]></title>
        <id>http://weinstockj.github.io/blog/2016/05/21/first-post!/</id>
        <link href="http://weinstockj.github.io/blog/2016/05/21/first-post!/">
        </link>
        <updated>2016-05-21T19:44:58Z</updated>
        <summary type="html"><![CDATA[<p>This is my hello world! Just for my personal notes, I thought it would be useful to describe how I created this blog. I have fairly limited web development experience and figured creating a blog would be a fun way to improve (the benefit of having a website is also nice!).</p>
<p>My development environment for this blog was Windows 10, working with node. I used the
<a href="http://yeoman.io/">Yeoman</a> scaffolding tool to launch this <a href="https://github.com/matthewbdaly/generator-simple-static-blog#readme">generator</a> written by
Matthew Daly. The generator made it fairly easy to spin up this blog. My workflow was something like editing files in <a href="atom.io">atom</a>, and then keeping <a href="http://www.mingw.org/">MinGW</a> (minimalist GNU) running in the background to switch between grunt and git commands. Writing posts is easy with markdown.</p>
]]></summary>
    </entry>
</feed>