<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>The Weak Learner</title>
        <description>A blog about programming and statistics</description>
        <link>http://weinstockj.github.io</link>
        <lastBuildDate>Fri, 22 Jul 2016 02:43:01 GMT</lastBuildDate>
        <docs>http://blogs.law.harvard.edu/tech/rss</docs>
        <copyright>Josh Weinstock 2016</copyright>
        <generator>Feed for Node.js</generator>
        <item>
            <title><![CDATA[Using a char-rnn on the R manual]]></title>
            <link>http://weinstockj.github.io/blog/2016/07/19/using-a-char-rnn-on-the-r-manual/</link>
            <guid>http://weinstockj.github.io/blog/2016/07/19/using-a-char-rnn-on-the-r-manual/</guid>
            <pubDate>Tue, 19 Jul 2016 01:52:26 GMT</pubDate>
            <description><![CDATA[<p>Character recurrent neural networks have become very popular in recent years in the deep learning community for learning probability distributions over sequences of characters. More concretely, the probably of an “o” given the sequence of letters
“hell” . There are many ways to model sequences of characters, and it does not have to be accomplished with either a recurrent neural network or on a character level. E.g., simple markov models can perform reasonably in this context (reasonably not defined..), or a model could be trained on words. I will not offer a more in depth explanation, but instead I’ll link to two posts on the matter which offer far more lucid explanations than I could ever offer on the subject.</p>
<p>Anyway, as far as I’m aware, the canonical blog post on the subject comes from Andrej Karpathy <a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/">here</a> . Karpathy open sourced a version of the network in the torch language. The model was rewritten to use Tensorflow in this implementation <a href="https://github.com/sherjilozair/char-rnn-tensorflow">here</a> . This is the code I used for this project, for no particular reason other than curiosity.</p>
<p>As far as I can tell, LSTM’s are generally more popular these days than recurrent neural networks. An excellent post on the subject is <a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/">here</a> .</p>
<p>These models can produce some entertaining results. A prime example is the <a href="https://twitter.com/deepdrumpf">@deepdrumpf</a> Twitter account, which tweets samples from a trained recurrent neural network.</p>
<p>In a more nerdy direction, I trained a char-rnn on the sexy corpus of text known as the <a href="https://cran.r-project.org/manuals.html">R manuals</a>. I also added a small sprinkle of text from <a href="http://adv-r.had.co.nz/">Hadley Wickham’s Advanced R.</a> . The hope being that my neural net would produce some fabulous new pieces of R Wizardry.</p>
<p>I trained my model in the official Tenorflow <a href="https://hub.docker.com/r/tensorflow/tensorflow/">docker</a> container. I did this to avoid all the headache of setting up the proper python / jupyter / Tensorflow enviroment. I trained the model with a single hidden layer with 350 hidden units, and some standard amount of dropout that I don’t remember. It took several hours since I trained it on the CPU of my laptop.</p>
<h2 id="the-incredible-results">The Incredible results</h2>
<blockquote>
versiol computing dur can be set to eady
containing your response.

Next: build update that you should use file if the representation on the following table: these can save a little might be imported from by information and opened by complex types are handled
used
to create them elseugh R installed in others. R malloc(), but is checked siges to implement frequently.
</blockquote>

<p>The spelling is decent - remember that the model has no concept of grammar and has to learn everything from the corpus.</p>
<p>This is mostly gibberish. =( . Let’s try another!</p>
<blockquote>
If you have the same assingment as needs to be in that environment, as not necessary to FORTRAN. Note that it is essential, for example shown that a ‘Method’ that does if a useful for a shared object. I’l book is the file see Lathest attaches the package task. If you need to get an installed header files in the convoltable to contribute Furbath, supply a 32-bit and write.table and those for the environment of the loop. The best common in R CMD check that we can in the reposi
</blockquote>  

<p>A little better this time. The model learned some stuff about header files and Fortran being parts that drive R. It also learned about the write.table function and R CMD CHECK.</p>
<p>Let’s do one last sample:</p>
<blockquote>
Function. Do not need duplication flags. To try the national expressions, only 02 and 1 is the more efficient to the command is better to take a parent of the model at least in front-end. You can remove Fortran CPUs should stit in an object in the default is defined in the previous might want to read libraries supplied for other useful returns. It is needed, the efficienchmarms to form Negatives. ‘A mile88 bytes are coerced to compute C++ extensions. You might won’t register them once things able th
</blockquote>

<p>Well I primed this sample with “function”, but looks like the model spit out some stuff about compiling and C++. Also another mention of Fortran here.</p>
<h3 id="ending-thoughts">Ending thoughts</h3>
<p>The results were not as amusing as I had hoped - perhaps that’s merely a product of this being a ridiculous endeavor. Anyway, it was worthwhile getting a little more familiar with Docker and Tensorflow. Obvious limitations include training a small network on a small corpus. The source for this is <a href="https://github.com/weinstockj/char_rnn_experiment">here</a>. </p>
]]></description>
            <content:encoded/>
        </item>
        <item>
            <title><![CDATA[Decorators in R]]></title>
            <link>http://weinstockj.github.io/blog/2016/06/08/decorators-in-r/</link>
            <guid>http://weinstockj.github.io/blog/2016/06/08/decorators-in-r/</guid>
            <pubDate>Wed, 08 Jun 2016 01:51:09 GMT</pubDate>
            <description><![CDATA[<p>I recently became interested in the idea of writing decorators in R, as the
title of this blog post may suggest. A decorator is a function that takes another
function as input, and extends the behavior in some manner. A use-case is when
you find yourself writing several functions, and each shares some small aspect
of functionality or code. A reasonable example is as follows.</p>
<p>Consider the case where you are writing several functions in R, each of which
takes some non-trivial amount of time to compute. You’d like to time each of
them. One approach would be the following:</p>
<pre><code>
important_task = function() {
  ptm = proc.time()
  # important stuff here
  seconds = (proc.time() - ptm)[[3]]
  cat(sprintf("time used: %.2f\n", seconds))
  # return whatever
}

another_important_task = function() {
  ptm = proc.time()
  # more important stuff here
  seconds = (proc.time() - ptm)[[3]]
  cat(sprintf("time used: %.2f\n", seconds))
  # return whatever
}
</code></pre>

<p>Another approach is to use a decorator. Let’s define our R decorator like so:</p>
<pre><code>
time = funtion(f) {
  function(...) {
    ptm = proc.time()
    result = f(...)  
    seconds = (proc.time() - ptm)[[3]]
    cat(sprintf("time used: %.2f\n", seconds))
    return(result)
  }
}
</code></pre>

<p>And then we can apply our decorator:</p>
<pre><code>
important_task_decorated = time(important_task)
</code></pre>

<p>For additional style points, we can define an infix operator to represent this operation:</p>
<pre><code>
`%decorate%` = function(decorator, f) {
  decorator(f)
}

important_task = time %decorate% function() cat("important stuff\n")
</code></pre>

<p>The chief benefit from my perspective is that things are now a little more modular.
I could change the decorator to write out the timings, or some other message,
into a log if I wished. This would then modify every function that I decorate,
which is better in my estimation than going into each function and changing whatever the shared functionality is. Less duplicated code is a good thing. The downsides
include more cognitive overhead induced by the new syntax, and I could envision certain scenarios in which this approach obfuscates the behavior of a given function.</p>
<h3 id="a-digression-on-scoping-rules-in-r">A digression on scoping rules in R</h3>
<p>The ability to write closures in R enables this technique. An excellent reference on the subject comes from <a href="http://adv-r.had.co.nz/Functional-programming.html#closures">Hadley</a> . I will note
that one potential area of confusion that could arise in this context is relating to R’s scoping rules. If you used the decorator to create an object that the decorated function depends on, the result would be an error that the object can’t be found by the decorated function. This is because R uses lexical scoping as opposed to dynamic scoping. In this context, this means that the enclosing environment of functions when they are created is very important. Here’s an example of where this would fail:</p>
<p><pre><code>
decorator = function(f) function(…) {
  a = 5
  f(…)
}
f = decorator %decorate% function() a + 2
</pre></code></p>
<p>To make this work, you’d have to change the enclosure of f to the anonymous
function in the decorator.</p>
<p><pre><code>
decorator = function(f) function(…) {
  a = 5
  environment(f) = environment()
  f(…)
}
f = decorator %decorate% function() a + 2
</pre></code></p>
<p>Now, when f does not see the variable <code>a</code> in its scope, it can search
in its enclosure, and it will find the <code>a</code> defined.</p>
<p>For more on this, see <code>?environment</code> for the following:</p>
<blockquote>
<p>Environments consist of a frame, or collection of named objects, and a pointer to an enclosing environment. The most common example is the frame of variables local to a function call; its enclosure is the environment where the function was defined (unless changed subsequently). The enclosing environment is distinguished from the parent frame: the latter (returned by parent.frame) refers to the environment of the caller of a function. Since confusion is so easy, it is best never to use ‘parent’ in connection with an environment (despite the presence of the function parent.env).</p>
<p>When get or exists search an environment with the default inherits = TRUE, they look for the variable in the frame, then in the enclosing frame, and so on.</p>
<p>The global environment .GlobalEnv, more often known as the user’s workspace, is the first item on the search path. It can also be accessed by globalenv(). On the search path, each item’s enclosure is the next item.</p>
<p>The object .BaseNamespaceEnv is the namespace environment for the base package. The environment of the base package itself is available as baseenv().</p>
<p>If one follows the chain of enclosures found by repeatedly calling parent.env from any environment, eventually one reaches the empty environment emptyenv(), into which nothing may be assigned.</p>
<p>The replacement function parent.env&lt;- is extremely dangerous as it can be used to destructively change environments in ways that violate assumptions made by the internal C code. It may be removed in the near future.</p>
<p>The replacement form of environment, is.environment, baseenv, emptyenv and globalenv are primitive functions.</p>
</blockquote>
<p>System environments, such as the base, global and empty environments, have names as do the package and namespace environments and those generated by attach(). Other environments can be named by giving a “name” attribute, but this needs to be done with care as environments have unusual copying semantics.</p>
<h3 id="finishing-thoughts">Finishing thoughts</h3>
<p>I don’t know if I’ll actually make use of this technique in the future, but it
seemed fun and fulfilled a use-case for me earlier today, so figured I’d spend some
time to write up the process.</p>
]]></description>
            <content:encoded/>
        </item>
        <item>
            <title><![CDATA[Reading in data in Julia, R, and Python]]></title>
            <link>http://weinstockj.github.io/blog/2016/06/04/reading-in-data-in-julia-r-and-python/</link>
            <guid>http://weinstockj.github.io/blog/2016/06/04/reading-in-data-in-julia-r-and-python/</guid>
            <pubDate>Sat, 04 Jun 2016 02:24:29 GMT</pubDate>
            <description><![CDATA[<p>I’ve been fairly interested in the <a href="http://julialang.org/">Julia</a> programming language recently. Haven’t heard of it? From the project website:  “Julia is a high-level, high-performance dynamic programming language for technical computing.”</p>
<p>From what I understand, it’s a programming language intended
to provide a high-level programming interface with similar
features to R / Python / Matlab at near C-level speed. Sounds
pretty intriguing right? The language is fairly new, so its ecosystem is not as mature as R’s or Python’s.</p>
<p>At my job I attempted to do some of my work in Julia a couple months back, but honestly never got much further than reading in a .csv into memory.
Anecdotally, it seemed pretty slow to read in data, as well as having very high memory usage. This gave my the sense that Julia was maybe not quite appropriate for my purposes if I couldn’t efficiently read in and store a simple .csv.
Naturally, this may have also been a result of my lack of familiarity with the language.</p>
<p>I decided to play around with the language again a couple months later, and downloaded the development version of Julia 0.5.0. The simple benchmark I came up with was:</p>
<ol>
<li>Download  this <a href="https://raw.githubusercontent.com/hadley/nycflights13/master/data-raw/airports.csv">airports data</a></li>
<li>Read in file to a data frame</li>
</ol>
<p>In R and Python I was capable of doing both steps at once,
while with Julia I had to download the file separately, and then read in the file, which is no big deal.</p>
<p>I chose this dataset, popularized by <a href="https://github.com/hadley">Hadley Wickham</a> in some of the vignettes
of his R packages. I don’t know the origins of the dataset.</p>
<p>Here are the commands I used to do this analysis:</p>
<h4 id="r-3-2-1">R 3.2.1</h4>
<pre><code>
flights = read.csv("https://raw.githubusercontent.com/hadley/nycflights13/master/data-raw/airports.csv")
pryr::object_size(flights)
</code></pre>

<h4 id="python-2-7-10">Python 2.7.10</h4>
<pre><code>
import pandas as pd
flights = pd.read_csv("https://raw.githubusercontent.com/hadley/nycflights13/master/data-raw/airports.csv")
flights.values.nbytes
</code></pre>

<h4 id="julia-0-5-0-dev">Julia 0.5.0-dev</h4>
<pre><code>
using DataFrames
download("https://raw.githubusercontent.com/hadley/nycflights13/master/data-raw/airports.csv", "airpots.csv")
df = readtable("airpots.csv")
whos(r"df")
</code></pre>

<h2 id="results">Results</h2>
<table>
<thead>
<tr>
<th>language</th>
<th>RAM</th>
<th>time (sec)</th>
</tr>
</thead>
<tbody>
<tr>
<td>R</td>
<td>235 KB</td>
<td>0.20</td>
</tr>
<tr>
<td>Python</td>
<td>78 KB</td>
<td>0.19</td>
</tr>
<tr>
<td>Julia</td>
<td>143 KB</td>
<td>5.45</td>
</tr>
</tbody>
</table>
<h3 id="caveats">Caveats</h3>
<p>My sense is that this was probably a dumb benchmark. Internet download speeds can be variable, and I didn’t run this on a very fast internet connection. For Julia I also only timed the <code>readtable</code> function and ignored the <code>download</code> aspect, out of laziness.</p>
<h2 id="discussion">Discussion</h2>
<p>According to this benchmark, R was the least efficient at storing this data in terms of memory usage. My sense is that this is probably related to the fact that R doesn’t store numeric data very efficiently since there are no primitive types. By that I mean a single integer in R will take up 48 bytes of memory, when clearly you don’t need 48 bytes to store a single integer. It’s because the resulting object is actually a vector. In Python, storing an integer (via <code>var = 1</code>) takes 24 bytes, and in Julia it takes just 8 bytes. So yea, R is 6
times less memory efficient than Julia for storing a single int. Perhaps this isn’t super relevant to this discussion because there’s a lot more going on in <code>dataframe</code> structures than that.</p>
<p>In terms of speed, clearly Julia was much slower here than R or Python. Obviously I didn’t even bother with faster R functions to read in data like <code>data.table::fread</code> or <code>readr::read_csv</code> . I don’t know very much about the data frame implementation or the <code>readtable</code> function, so I won’t hazard a guess as to why we observed this result. I will conclude by just pointing out that this was a silly benchmark, and it’s my sense that Julia was constructed with more in mind than performing well on this benchmark. This was more to satisfy my curiosity than an attempt at a serious benchmark.</p>
]]></description>
            <content:encoded/>
        </item>
        <item>
            <title><![CDATA[First post!]]></title>
            <link>http://weinstockj.github.io/blog/2016/05/21/first-post!/</link>
            <guid>http://weinstockj.github.io/blog/2016/05/21/first-post!/</guid>
            <pubDate>Sat, 21 May 2016 19:44:58 GMT</pubDate>
            <description><![CDATA[<p>This is my hello world! Just for my personal notes, I thought it would be useful to describe how I created this blog. I have fairly limited web development experience and figured creating a blog would be a fun way to improve (the benefit of having a website is also nice!).</p>
<p>My development environment for this blog was Windows 10, working with node. I used the
<a href="http://yeoman.io/">Yeoman</a> scaffolding tool to launch this <a href="https://github.com/matthewbdaly/generator-simple-static-blog#readme">generator</a> written by
Matthew Daly. The generator made it fairly easy to spin up this blog. My workflow was something like editing files in <a href="atom.io">atom</a>, and then keeping <a href="http://www.mingw.org/">MinGW</a> (minimalist GNU) running in the background to switch between grunt and git commands. Writing posts is easy with markdown.</p>
]]></description>
            <content:encoded/>
        </item>
    </channel>
</rss>